# Solution for Natural Language Processing with Disaster Tweets

## Overview

This repository includes solutions for text classification on disaster tweets using various models. Two notable notebooks are:

1. **[nlp-twitter-bert.ipynb](https://github.com/Omadzze/NLP-twitter/blob/main/nlp-twitter-bert.ipynb)**:
   - **Description**: This notebook details the use of a BERT model for text classification. The process includes data preprocessing, where unnecessary elements such as links, emojis, and usernames were removed, followed by tokenization and fine-tuning.
   - **BERT Model Score**: 0.82163

2. **[nlp-twitter-gemma.ipynb](https://github.com/Omadzze/NLP-twitter/blob/main/nlp-twitter-gemma.ipynb)**:
   - **Description**: This notebook presents the Gemma model, which has been shown to perform better than the BERT model in this context.
   - **Gemma Model Score**: 0.82899

## Results

- **Gemma Model Score**: 0.82899
- **BERT Model Score**: 0.82163

The Gemma model achieves a slightly higher performance compared to the BERT model. For detailed implementation and results, refer to the respective notebooks.
